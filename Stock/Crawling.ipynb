{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import ssl\n",
    "\n",
    "def GetKospi200():     \n",
    "    stockDic = dict()\n",
    "    lastPageNum = 0\n",
    "\n",
    "    # 마지막 페이지 찾기\n",
    "    base_url = \"http://finance.naver.com/sise/entryJongmok.nhn?&page=\"\n",
    "    target_url = base_url + str(1)\n",
    "    context = ssl._create_unverified_context()\n",
    "    # soup = BeautifulSoup(urllib.request.urlopen(target_url).read(), \"lxml\")\n",
    "    soup = BeautifulSoup(urllib.request.urlopen(target_url, context=context).read().decode('euc-kr', 'ignore'), \"lxml\")\n",
    "    for item in soup.find_all('td'):\n",
    "        if item.has_attr('class') and 'pgRR' in item['class']:\n",
    "            lastPageNum = int(str(item.a['href']).replace('/sise/entryJongmok.nhn?&page=', ''))\n",
    "\n",
    "    for i in range(1, lastPageNum+1):\n",
    "        target_url = base_url + str(i)\n",
    "        # soup = BeautifulSoup(urllib.request.urlopen(target_url).read(), \"lxml\")\n",
    "        soup = BeautifulSoup(urllib.request.urlopen(target_url, context=context).read().decode('euc-kr', 'ignore'), \"lxml\")\n",
    "        postNoList = soup.find_all('a')\n",
    "\n",
    "\n",
    "        # 종목코드와 종목명 담기\n",
    "        for item in postNoList:\n",
    "            if item.has_attr('target') and '_parent' in item['target'] and item.has_attr('href'):\n",
    "                if str(item['href']).startswith('/item/main.nhn?code='):\n",
    "                    stockDic[str(item['href']).replace('/item/main.nhn?code=', '')] = item.text\n",
    "    return stockDic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def GetPriceData(item):    \n",
    "    \n",
    "    # print(item)\n",
    "    code = item[0]\n",
    "    name = item[1]\n",
    "                \n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'}\n",
    "    url = \"http://finance.naver.com/item/sise_day.nhn?code=\" + code\n",
    "    page = \"&page=\"\n",
    "    idx = 1\n",
    "#     datetimeList = []\n",
    "#     closePriceList = []\n",
    "#     startPriceList = []\n",
    "#     minPriceList = []\n",
    "#     maxPriceList = []\n",
    "#     amountList = []\n",
    "\n",
    "\n",
    "    bBool = True\n",
    "    outputFileName = directory + code + '.csv'\n",
    "    \n",
    "    df = pd.read_csv(outputFileName)\n",
    "\n",
    "    \n",
    "    with open(outputFileName, 'a') as f:\n",
    "        while bBool:\n",
    "            fullAddr = url + page + str(idx)\n",
    "\n",
    "            source_code = requests.get(fullAddr, headers = headers)\n",
    "            if source_code is None:\n",
    "                break\n",
    "\n",
    "            soup = BeautifulSoup(source_code.text,\"lxml\")\n",
    "            if soup.find('td', class_='on').find('a').text != str(idx):\n",
    "                break\n",
    "\n",
    "            for tr in filter(lambda x:x.get(\"onmouseout\") is not None, soup.find_all(\"tr\")):\n",
    "                if tr.find(\"span\",class_ = \"tah p10 gray03\") is None:\n",
    "                    # 가격데이터가 없으면 False로 빠져나옴\n",
    "                    bBool = False\n",
    "\n",
    "                else:\n",
    "                    tDate = tr.find(\"span\",class_ = \"tah p10 gray03\").text\n",
    "                    cPrice = tr.find_all(\"span\",class_ = \"tah p11\")\n",
    "                    sIdx = 1\n",
    "\n",
    "                    if len(cPrice) != 5 :\n",
    "                        sIdx = 2\n",
    "\n",
    "                    dt = tDate.replace(\".\" ,\"-\")\n",
    "                    if (df[\"date\"] == dt).sum() > 0:                        \n",
    "#                         print(dt, \" 가격존재 \")\n",
    "                        f.close()\n",
    "                        return\n",
    "\n",
    "                    pClose = float(cPrice[0].text.replace(\",\" ,\"\"))\n",
    "                    pStart = float(cPrice[sIdx].text.replace(\",\" ,\"\"))\n",
    "                    sIdx += 1\n",
    "                    pMax   = float(cPrice[sIdx].text.replace(\",\" ,\"\"))\n",
    "                    sIdx += 1\n",
    "                    pMin   = float(cPrice[sIdx].text.replace(\",\" ,\"\"))\n",
    "                    sIdx += 1\n",
    "                    amount = float(cPrice[sIdx].text.replace(\",\" ,\"\"))\n",
    "\n",
    "                    stockList = []\n",
    "                    stockList.append(dt)\n",
    "                    stockList.append(code)\n",
    "                    stockList.append(pStart)\n",
    "                    stockList.append(pClose)\n",
    "                    stockList.append(pMin)\n",
    "                    stockList.append(pMax)\n",
    "                    stockList.append(amount)                \n",
    "                    f.writelines(\",\".join([str(x) for x in stockList]) + '\\n') \n",
    "            idx += 1\n",
    "    f.close()\n",
    "    \n",
    "    # 투자정보\n",
    "    # totalCnt = []  # 상장주식수\n",
    "    # forignerHaveLimit = []  # 외국인한도보유주식수\n",
    "    # forignerHaveCnt = []  # 외국인보유주식수\n",
    "    # max52week = []  # 52주 최고\n",
    "    # min52week = []  # 52주 최저\n",
    "    # per = []\n",
    "    # eps = []\n",
    "    # per_eps_date = []\n",
    "    # estimate_per = []  # 추정 PER\n",
    "    # estimate_eps = []  # 추정 EPS\n",
    "    # pbr = []\n",
    "    # bps = []\n",
    "    # pbr_bps_date = []\n",
    "    # dvr = []  # 배당수익\n",
    "\n",
    "    url2 = \"https://finance.naver.com/item/main.nhn?code=\" + code\n",
    "    source_code = requests.get(url2, headers = headers)\n",
    "    if source_code is None:\n",
    "        pass\n",
    "    else:\n",
    "        soup = BeautifulSoup(source_code.text, \"lxml\")\n",
    "        \n",
    "        totalCnt = soup.find(id='tab_con1').find_all('em')[2].text.replace(',', '').replace('N/A', '0')\n",
    "        forignerHaveLimit = soup.find(id='tab_con1').find_all('em')[5].text.replace(',', '').replace('N/A', '0')\n",
    "        forignerHaveCnt = soup.find(id='tab_con1').find_all('em')[6].text.replace(',', '').replace('N/A', '0')\n",
    "        max52week = soup.find(id='tab_con1').find_all('em')[10].text.replace(',', '').replace('N/A', '0')\n",
    "        min52week = soup.find(id='tab_con1').find_all('em')[11].text.replace(',', '').replace('N/A', '0')\n",
    "        per = soup.find(id='tab_con1').find_all('em')[12].text.replace(',', '').replace('N/A', '0')\n",
    "        eps = soup.find(id='tab_con1').find_all('em')[13].text.replace(',', '').replace('N/A', '0')\n",
    "        per_eps_date = soup.find(id='tab_con1').find_all('span', class_='date')[0].text.replace('(','').replace(')','') if len(soup.find(id='tab_con1').find_all('span', class_='date')) > 0 else \"\"\n",
    "        estimate_per = soup.find(id='tab_con1').find_all('em')[14].text.replace(',', '').replace('N/A', '0')\n",
    "        estimate_eps = soup.find(id='tab_con1').find_all('em')[15].text.replace(',', '').replace('N/A', '0')\n",
    "        pbr = soup.find(id='tab_con1').find_all('em')[16].text.replace(',', '').replace('N/A', '0')\n",
    "        bps = soup.find(id='tab_con1').find_all('em')[17].text.replace(',', '').replace('N/A', '0')\n",
    "        pbr_bps_date = soup.find(id='tab_con1').find_all('span', class_='date')[1].text.replace('(','').replace(')','') if len(soup.find(id='tab_con1').find_all('span', class_='date')) > 1 else \"\"\n",
    "        dvr = soup.find(id='tab_con1').find_all('em')[18].text.replace(',', '').replace('N/A', '0')                \n",
    "        \n",
    "        financeList = []\n",
    "        financeList.append(datetime.today().strftime(\"%Y-%m-%d\"))\n",
    "        financeList.append(code)\n",
    "        financeList.append(totalCnt)\n",
    "        financeList.append(forignerHaveLimit)\n",
    "        financeList.append(forignerHaveCnt)\n",
    "        financeList.append(forignerHaveLimit)\n",
    "        financeList.append(forignerHaveCnt)\n",
    "        financeList.append(max52week)\n",
    "        financeList.append(min52week)\n",
    "        financeList.append(per)\n",
    "        financeList.append(eps)\n",
    "        financeList.append(per_eps_date)\n",
    "        financeList.append(estimate_per)\n",
    "        financeList.append(estimate_eps)\n",
    "        financeList.append(pbr)\n",
    "        financeList.append(bps)\n",
    "        financeList.append(pbr_bps_date)\n",
    "        financeList.append(dvr)  \n",
    "        financeFileName = 'data/' + 'stock_finance_data.csv'\n",
    "        with open(financeFileName, 'a') as f:\n",
    "            f.writelines(\",\".join([str(x) for x in financeList]) + '\\n') \n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests \n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def crawling():\n",
    "    file_list = os.listdir('data')\n",
    "    exist_list = []\n",
    "    for file in file_list:\n",
    "        if 'finance' not in file and '.csv' in file:\n",
    "            exist_list.append(file)\n",
    "\n",
    "    directory = 'data/'\n",
    "    stockDict = GetKospi200()\n",
    "    # stockDict = {'192400' : '쿠쿠홀딩스'}\n",
    "\n",
    "    kospiListFile = \"kospi_list.csv\"\n",
    "    bFlag = False\n",
    "    if os.path.exists(directory+kospiListFile):\n",
    "        bFlag = bool((pd.read_csv(directory+kospiListFile, names=[\"date\", \"code\", \"name\"], header=None)[\"date\"] == datetime.today().strftime(\"%Y-%m-%d\")).sum())\n",
    "    \n",
    "    with open(directory + \"/\" + kospiListFile, 'a') as f:\n",
    "        for key in stockDict.keys():\n",
    "            if not bFlag:        \n",
    "                l = []\n",
    "                l.append(datetime.today().strftime(\"%Y-%m-%d\"))\n",
    "                l.append(key)\n",
    "                l.append(stockDict[key])\n",
    "                f.writelines(\",\".join([str(x) for x in l]) + '\\n') \n",
    "\n",
    "            if str(key) not in exist_list:\n",
    "                target = (key, stockDict[key])                \n",
    "                GetPriceData(target)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정날짜 데이터 제거 및 reset_index\n",
    "import pandas as pd\n",
    "def removeData(date = \"2021-02-26\"):\n",
    "    directory = 'data'\n",
    "    file_list = os.listdir(directory)\n",
    "\n",
    "    for file in file_list:\n",
    "        if 'finance' not in file and '.csv' in file and 'kospi' not in file:   \n",
    "            print(file)\n",
    "            df = pd.read_csv(directory + \"/\" + file)\n",
    "            if \"Unnamed: 0\" in df.columns:\n",
    "                df = pd.read_csv(directory + \"/\" + file).drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "            if (df[\"date\"] == date).sum() > 0:\n",
    "                df = df.drop(df[df[\"date\"] == date].index)\n",
    "                df.to_csv(directory + \"/\" + file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정날짜 데이터 제거 및 reset_index\n",
    "import pandas as pd\n",
    "def resetIndex():\n",
    "#     cols = [\"date\", \"code\", \"start\", \"close\", \"min\", \"max\", \"amount\"]\n",
    "    directory = 'data'\n",
    "    file_list = os.listdir(directory)\n",
    "\n",
    "    for file in file_list:\n",
    "        if 'finance' not in file and '.csv' in file and 'kospi' not in file:     \n",
    "            print(file)\n",
    "            df = pd.read_csv(directory + \"/\" + file)\n",
    "            if \"Unnamed: 0\" in df.columns:\n",
    "                df = pd.read_csv(directory + \"/\" + file).drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "            df = df.sort_values(by=\"date\").reset_index().drop(\"index\", axis=1)\n",
    "            df.to_csv(directory + \"/\" + file, index=False)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "005380.csv\n",
      "001680.csv\n",
      "017800.csv\n",
      "272210.csv\n",
      "115390.csv\n",
      "241590.csv\n",
      "000210.csv\n",
      "108670.csv\n",
      "105630.csv\n",
      "000990.csv\n",
      "003490.csv\n",
      "049770.csv\n",
      "192820.csv\n",
      "064350.csv\n",
      "003240.csv\n",
      "005180.csv\n",
      "039490.csv\n",
      "069260.csv\n",
      "139480.csv\n",
      "316140.csv\n",
      "018880.csv\n",
      "006260.csv\n",
      "284740.csv\n",
      "018260.csv\n",
      "282330.csv\n",
      "192400.csv\n",
      "035720.csv\n",
      "112610.csv\n",
      "145990.csv\n",
      "035250.csv\n",
      "003090.csv\n",
      "010950.csv\n",
      "064960.csv\n",
      "001120.csv\n",
      "009540.csv\n",
      "001450.csv\n",
      "185750.csv\n",
      "128940.csv\n",
      "031430.csv\n",
      "009150.csv\n",
      "001040.csv\n",
      "033780.csv\n",
      "009420.csv\n",
      "008930.csv\n",
      "003520.csv\n",
      "036570.csv\n",
      "120110.csv\n",
      "000270.csv\n",
      "016360.csv\n",
      "009240.csv\n",
      "000660.csv\n",
      "352820.csv\n",
      "001230.csv\n",
      "001740.csv\n",
      "008770.csv\n",
      "207940.csv\n",
      "326030.csv\n",
      "021240.csv\n",
      "005490.csv\n",
      "267250.csv\n",
      "010060.csv\n",
      "024110.csv\n",
      "006400.csv\n",
      "294870.csv\n",
      "003550.csv\n",
      "036460.csv\n",
      "020000.csv\n",
      "103140.csv\n",
      "029780.csv\n",
      "214320.csv\n",
      "079160.csv\n",
      "011790.csv\n",
      "000070.csv\n",
      "004000.csv\n",
      "005440.csv\n",
      "096770.csv\n",
      "011780.csv\n",
      "014820.csv\n",
      "030000.csv\n",
      "032830.csv\n",
      "008560.csv\n",
      "000100.csv\n",
      "023530.csv\n",
      "035420.csv\n",
      "004170.csv\n",
      "020560.csv\n",
      "052690.csv\n",
      "204320.csv\n",
      "071840.csv\n",
      "138930.csv\n",
      "001800.csv\n",
      "028260.csv\n",
      "161890.csv\n",
      "003230.csv\n",
      "006360.csv\n",
      "028670.csv\n",
      "051600.csv\n",
      "005250.csv\n",
      "030200.csv\n",
      "000670.csv\n",
      "004370.csv\n",
      "000880.csv\n",
      "004990.csv\n",
      "073240.csv\n",
      "007700.csv\n",
      "069620.csv\n",
      "068270.csv\n",
      "375500.csv\n",
      "111770.csv\n",
      "042670.csv\n",
      "007310.csv\n",
      "011200.csv\n",
      "017670.csv\n",
      "034730.csv\n",
      "000720.csv\n",
      "012330.csv\n",
      "005300.csv\n",
      "086790.csv\n",
      "004020.csv\n",
      "006390.csv\n",
      "251270.csv\n",
      "079550.csv\n",
      "071050.csv\n",
      "088350.csv\n",
      "047050.csv\n",
      "010120.csv\n",
      "004800.csv\n",
      "003410.csv\n",
      "007070.csv\n",
      "028050.csv\n",
      "003000.csv\n",
      "192080.csv\n",
      "016380.csv\n",
      "020150.csv\n",
      "011170.csv\n",
      "005930.csv\n",
      "078930.csv\n",
      "047040.csv\n",
      "010130.csv\n",
      "000120.csv\n",
      "057050.csv\n",
      "180640.csv\n",
      "012450.csv\n",
      "069960.csv\n",
      "093370.csv\n",
      "006800.csv\n",
      "000240.csv\n",
      "008350.csv\n",
      "271560.csv\n",
      "042660.csv\n",
      "011210.csv\n",
      "032350.csv\n",
      "000080.csv\n",
      "002380.csv\n",
      "051900.csv\n",
      "047810.csv\n",
      "336260.csv\n",
      "002790.csv\n",
      "014680.csv\n",
      "066570.csv\n",
      "000150.csv\n",
      "034020.csv\n",
      "009410.csv\n",
      "010140.csv\n",
      "019170.csv\n",
      "000810.csv\n",
      "005940.csv\n",
      "026960.csv\n",
      "004490.csv\n",
      "097950.csv\n",
      "015760.csv\n",
      "003670.csv\n",
      "018250.csv\n",
      "013890.csv\n",
      "034220.csv\n",
      "005610.csv\n",
      "086280.csv\n",
      "114090.csv\n",
      "012630.csv\n",
      "012750.csv\n",
      "010620.csv\n",
      "032640.csv\n",
      "090430.csv\n",
      "006650.csv\n",
      "002350.csv\n",
      "241560.csv\n",
      "055550.csv\n",
      "007570.csv\n",
      "006120.csv\n",
      "005830.csv\n",
      "009830.csv\n",
      "285130.csv\n",
      "011070.csv\n",
      "105560.csv\n",
      "001060.csv\n",
      "081660.csv\n",
      "003850.csv\n",
      "006280.csv\n",
      "161390.csv\n",
      "051910.csv\n",
      "010780.csv\n"
     ]
    }
   ],
   "source": [
    "resetIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>code</th>\n",
       "      <th>start</th>\n",
       "      <th>close</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2002-07-16</td>\n",
       "      <td>9240</td>\n",
       "      <td>6020.0</td>\n",
       "      <td>6920.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>6920.0</td>\n",
       "      <td>562319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2002-07-18</td>\n",
       "      <td>9240</td>\n",
       "      <td>7950.0</td>\n",
       "      <td>7950.0</td>\n",
       "      <td>7950.0</td>\n",
       "      <td>7950.0</td>\n",
       "      <td>62853.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2002-07-19</td>\n",
       "      <td>9240</td>\n",
       "      <td>9140.0</td>\n",
       "      <td>9140.0</td>\n",
       "      <td>8830.0</td>\n",
       "      <td>9140.0</td>\n",
       "      <td>2406392.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2002-07-22</td>\n",
       "      <td>9240</td>\n",
       "      <td>9700.0</td>\n",
       "      <td>10500.0</td>\n",
       "      <td>9500.0</td>\n",
       "      <td>10500.0</td>\n",
       "      <td>2124721.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2002-07-23</td>\n",
       "      <td>9240</td>\n",
       "      <td>12050.0</td>\n",
       "      <td>12050.0</td>\n",
       "      <td>11650.0</td>\n",
       "      <td>12050.0</td>\n",
       "      <td>1605507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>4599</td>\n",
       "      <td>2021-02-19</td>\n",
       "      <td>9240</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>101000.0</td>\n",
       "      <td>99000.0</td>\n",
       "      <td>101500.0</td>\n",
       "      <td>67547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>4600</td>\n",
       "      <td>2021-02-22</td>\n",
       "      <td>9240</td>\n",
       "      <td>101000.0</td>\n",
       "      <td>99200.0</td>\n",
       "      <td>97700.0</td>\n",
       "      <td>101000.0</td>\n",
       "      <td>112343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4601</th>\n",
       "      <td>4601</td>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>9240</td>\n",
       "      <td>98700.0</td>\n",
       "      <td>100500.0</td>\n",
       "      <td>97600.0</td>\n",
       "      <td>102500.0</td>\n",
       "      <td>84469.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4602</th>\n",
       "      <td>4602</td>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>9240</td>\n",
       "      <td>100500.0</td>\n",
       "      <td>98700.0</td>\n",
       "      <td>98000.0</td>\n",
       "      <td>100500.0</td>\n",
       "      <td>72979.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>4603</td>\n",
       "      <td>2021-02-25</td>\n",
       "      <td>9240</td>\n",
       "      <td>98800.0</td>\n",
       "      <td>99500.0</td>\n",
       "      <td>98100.0</td>\n",
       "      <td>100500.0</td>\n",
       "      <td>44233.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4604 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        date  code     start     close      min       max  \\\n",
       "0              0  2002-07-16  9240    6020.0    6920.0   6000.0    6920.0   \n",
       "1              1  2002-07-18  9240    7950.0    7950.0   7950.0    7950.0   \n",
       "2              2  2002-07-19  9240    9140.0    9140.0   8830.0    9140.0   \n",
       "3              3  2002-07-22  9240    9700.0   10500.0   9500.0   10500.0   \n",
       "4              4  2002-07-23  9240   12050.0   12050.0  11650.0   12050.0   \n",
       "...          ...         ...   ...       ...       ...      ...       ...   \n",
       "4599        4599  2021-02-19  9240  100000.0  101000.0  99000.0  101500.0   \n",
       "4600        4600  2021-02-22  9240  101000.0   99200.0  97700.0  101000.0   \n",
       "4601        4601  2021-02-23  9240   98700.0  100500.0  97600.0  102500.0   \n",
       "4602        4602  2021-02-24  9240  100500.0   98700.0  98000.0  100500.0   \n",
       "4603        4603  2021-02-25  9240   98800.0   99500.0  98100.0  100500.0   \n",
       "\n",
       "         amount  \n",
       "0      562319.0  \n",
       "1       62853.0  \n",
       "2     2406392.0  \n",
       "3     2124721.0  \n",
       "4     1605507.0  \n",
       "...         ...  \n",
       "4599    67547.0  \n",
       "4600   112343.0  \n",
       "4601    84469.0  \n",
       "4602    72979.0  \n",
       "4603    44233.0  \n",
       "\n",
       "[4604 rows x 8 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"data\" + \"/\" + \"009240.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
